####################################################################################


====================================================================================
git vs gitlab
====================================================================================
Git (СКВ, VCS, Version Control Systems) — распределённая система контроля версий, которая даёт возможность разработчикам отслеживать изменения в файлах и работать над одним проектом совместно с коллегами. Она была разработана в 2005 году Линусом Торвальдсом, создателем Linux, чтобы другие разработчики могли вносить свой вклад в ядро Linux.
Существует три типа СКВ: локальная, централизованная и распределённая.
---------------------
Преимущества Git:
Бесплатный и open-source.
Небольшой и быстрый.
Резервное копирование.
Простое ветвление.
---------------------
GitHub — сервис онлайн-хостинга репозиториев, обладающий всеми функциями распределённого контроля версий и функциональностью управления исходным кодом — всё, что поддерживает Git и даже больше. 
---------------------
GitLab — это еще один веб-репозиторий git, который набирает популярность среди разработчиков проектов с открытым исходным кодом.
---------------------
В отличие от GitHub, GitLab предлагает бесплатные частные репозитории для проектов с открытым исходным кодом.
GitHub делает упор на высокую доступность и производительность своей инфраструктуры и делегирует другие сложные функции сторонним инструментам.
---------------------
GitLab, наоборот, фокусируется на включении всех функций на одной проверенной и хорошо интегрированной платформе; он обеспечивает все для полного жизненного цикла DevOps под одной крышей. 
---------------------
Фактически, если вы войдете на сайт GitHub, вам будет сложно думать, что вы не на GitLab. За прошедшие годы две службы управления репозиториями взяли друг у друга лучшие функции и интегрировались в свои платформы.
---------------------
Вот некоторые общие функции:
Запрос изменение (pull request)
Сторонние интеграции
Вилка (fork) / клонирование репозитория
Ревью кода
Фрагменты кода
Отслеживание проблем
Расширенное управление разрешениями
Поддержка Markdown (облегчённый язык разметки, созданный с целью обозначения форматирования в простом тексте, с максимальным сохранением его читаемости человеком, и пригодный для машинного преобразования в языки для продвинутых публикаций (HTML, Rich Text и других).)
====================================================================================


====================================================================================
gitlab ci vs jenkins
====================================================================================
Jenkins — это широко известный, гибкий CI/CD-инструмент, предназначенный для автоматизации множества задач, связанных с программными проектами. Jenkins полностью написан на Java, он выпущен под лицензией MIT. Он обладает мощным набором возможностей, направленных на автоматизацию задач, связанных со сборкой, тестированием, развёртыванием, интеграцией, выпуском программного обеспечения.
---------------------
Jenkins может работать на платформах macOS, Windows и Linux. Он может функционировать и в среде Docker, что позволяет организовать единообразное и быстрое выполнение автоматизированных задач. Этот инструмент, кроме того, может выполняться в виде сервлета (Сервлет является интерфейсом Java, реализация которого расширяет функциональные возможности сервера. Сервлет взаимодействует с клиентами посредством принципа запрос-ответ.) в контейнерах, поддерживающих Java, в таких, как Apache Tomcat и GlassFish. Установка Jenkins качественно документирована.
---------------------
Разработчики Jenkins создали ещё один проект, Jenkins X, который рассчитан на работу в среде Kubernetes. В Jenkins X интегрированы Helm, сервер Jenkins CI/CD, Kubernetes и другие инструменты, предназначенные для создания CI/CD-конвейеров, соответствующих передовым методам DevOps. Например, здесь используется GitOps.
---------------------
Плюсы Jenkins:
Среди широко известных особенностей Jenkins можно отметить простоту настройки, высокий уровень автоматизации различных операций и отличную документацию. 
---------------------
Развитая экосистема плагинов
В настоящее время существует более 1500 плагинов для Jenkins.
---------------------
Простая установка и настройка
---------------------
Наличие REST API
---------------------
Поддержка параллельного выполнения задач
Выполнение тестирования кода можно ускорить за счёт организации параллельной сборки проекта с использованием различных виртуальных машин.
---------------------
Поддержка работы в распределённых средах
====================================================================================
GitLab CI/CD
---------------------
GitLab CI/CD и основной проект GitLab написаны на Ruby и на Go. Они выпущены под лицензией MIT.
---------------------
Популярность
Это, к тому же, бесплатный CI/CD-инструмент, встроенный в платформу GitLab.
---------------------
Поддержка GitLab Pages и Jekyll
Jekyll — это генератор статических сайтов, который можно использовать в рамках системы GitLab Pages для создания сайтов на основе GitLab-репозиториев. Система берёт исходные материалы и генерирует на их основе готовый статический сайт. Управлять внешним видом и возможностями таких сайтов можно, редактируя файл _config.yml, используемый Jekyll.
---------------------
 Автоматическое масштабирование CI-раннеров, можно серьёзно сэкономить на стоимости аренды серверных мощностей.
---------------------
GitLab CI/CD позволяет выполнять параллельное тестирование различных веток кода.
Результаты испытаний удобно анализировать в интерфейсе системы. Это выгодно отличает GitLab CI/CD от Jenkins.
---------------------
Ограничение доступа к репозиториям
---------------------
Различия                                         Jenkins      GitLab CI/CD   
Мониторинг производительности приложений	Отсутствует	Имеется
Поддержка	                                Отсутствует	Имеется
Установка	                                Требуется	Не требуется
---------------------
GitLab CI/CD может полностью контролировать Git-репозитории. Речь идёт об управлении ветками репозиториев и о некоторых других возможностях. А вот Jenkins, хотя и умеет работать с репозиториями, не даёт такого же уровня контроля над ними, как GitLab CI/CD.
GitLab CI/CD поддерживает развитые средства управления задачами, работающие на уровне проектов. Эта сторона Jenkins развита слабее.
====================================================================================


====================================================================================
ansible - bare or vm, helm - kuber, terraform - cloud servers
Ansible — это программное решение для удаленного управления конфигурациями.
Helm — это средство упаковки с открытым исходным кодом, которое помогает установить приложения Kubernetes и управлять их жизненным циклом
Terraform – это инструмент от компании Hashicorp, помогающий декларативно управлять инфраструктрой. В данном случае не приходится вручную создавать инстансы, сети и т.д. в консоли вашего облачного провайдера; достаточно написать конфигурацию, в которой будет изложено, как вы видите вашу будущую инфраструктуру. Такая конфигурация создается в человеко-читаемом текстовом формате. Если вы хотите изменить вашу инфраструктуру, то редактируете конфигурацию и запускаете terraform apply. Terraform направит вызовы API к вашему облачному провайдеру, чтобы привести инфраструктуру в соответствие с конфигурацией, указанной в этом файле.
====================================================================================


====================================================================================
git pull vs git fetch
Грубо говоря, по дефолту git pull — это шоткод для последовательности двух команд: git fetch (получение изменений с сервера) и git merge (сливание в локальную копию).
====================================================================================


====================================================================================
virtualisation vs containerisation.
https://www.itc.by/kontejnery-i-virtualnye-mashiny-v-chem-klyuchevye-razlichiya/
  вм      вм2     вм3         прилож. прилож. прилож.
прилож  прилож   прилож          д   о   к   е   р
  ос      ос       ос                   ос
    ги пер ви зор                     сер вер
         ОС 
       СЕРВЕР
       
Хотя слой контейнеров обеспечивает уровень логической изоляции между контейнерами, общая ОС может представлять собой единую точку отказа для всех контейнеров в системе. 
В отличие от ВМ, контейнеры не изменяются.  
Аналогичным образом, программное обеспечение, работающее в контейнерах, не обновляется, как традиционное ПО. Вместо этого обновления включаются в новый образ контейнера, который может быть развернут там, где это необходимо.
Контейнеры не перемещаются, а воссоздаются на целевых компьютерах перед уничтожением исходного экземпляра.
Большое количество контейнеров, возможное в среде центра обработки данных, может быстрее нагрузить пропускную способность локальной сети.
ВМ имеют небольшое преимущество в производительности, поскольку ВМ не сталкиваются с потенциальной конкуренцией общей ОС.
ВМ включают постоянное хранилище с виртуальным жестким диском. Контейнеры изначально работают из памяти и требуют тщательного использования инструментов хранения, таких как Docker Data Volumes, для сохранения данных контейнера после его уничтожения.
Контейнеры используют меньше вычислительных ресурсов.
Контейнеры меньше и требуют меньше ресурсов, чем виртуальные машины, поэтому контейнеры могут масштабироваться — создаваться или уничтожаться — гораздо быстрее, чем виртуальные машины.
ВМ используют отдельные ОС и приложения, поэтому недостатки в безопасности одной ВМ не распространяются на другие ВМ в среде. Контейнеры используют общую ОС и могут быть подвержены влиянию дефектов в ОС, поэтому они не так безопасны, как ВМ. Однако контейнеры могут работать внутри ВМ в рамках гибридного подхода к развертыванию, что может помочь локализовать потенциальные уязвимости безопасности.
Контейнеры не могут быть легко обновлены в режиме реального времени. Вместо этого файлы контейнеров обновляются и приводятся к определенным версиям, а затем новый файл образа может быть развернут для внедрения обновлений.

Все инструменты контейнеризации — будь то Docker, LXC или systemd-nspawn,— основываются на двух подсистемах ядра Linux: namespaces и cgroups.
---------------------
namespaces
---------------------
Пространство имён (англ. namespace) — это механизм ядра Linux, обеспечивающий изоляцию процессов друг от друга.

Пространство имён	Что изолирует
     PID	        PID процессов
     NETWORK  	 Сетевые устройства, стеки, порты и т.п.
     USER          	ID пользователей и групп
     MOUNT	        Точки монтирования
     IPC	   SystemV IPC, очереди сообщений POSIX
     UTS	      Имя хоста и доменное имя NIS
---------------------
cgroups
---------------------  
Но для контейнеризации одной лишь изоляции ресурсов недостаточно. Если мы запускаем какое-либо приложение в изолированном окружении, мы должны быть уверены в том, что этому приложению выделено достаточно ресурсов и что оно не будет потреблять лишние ресурсы, нарушая тем самым работу остальной системы. Для решения этой задачи в ядре Linux имеется специальный механизм — cgroups (сокращение от control groups, контрольные группы). 
====================================================================================


====================================================================================
Docker — программное обеспечение для автоматизации развёртывания и управления приложениями в средах с поддержкой контейнеризации, контейнеризатор приложений.
dockerfile best practices.
1.Использование нескольких команд RUN для установки пакетов повлияет на производительность и эффективность процесса сборки. Использование одной команды RUN для установки всех пакетов и зависимостей поможет создать один кэшируемый юнит вместо нескольких.
2.Использование образов меньшего размера способствует быстрому развертыванию и снижает возможности для атак. Удалите ненужные зависимости
RUN apt-get update && apt-get -y install --no-install-recommends
3.Используйте официальный образ Docker.
Не используйте для образа latest тег. Latest тег со временем может получать критические изменения.
Используйте минимальную версию сборки.если вы будете стараться избегать привычки включать ненужные пакеты и открывать ненужные порты, тем самым вы уменьшите поверхность для атаки.
 Осторожно выбирайте базовый образ для ваших контейнеров (имеется ввиду инструкция FROM).
 Почаще обновляйте свои образы. 
 Публикуйте наружу только те порты, которые нужны вашему приложению, и избегайте таких портов, как SSH (22).
4.Сборка из исходного кода в изолированной (consistent) среде.
Мы должны избегать создания приложений в локальной среде.
5.Рекомендуется использовать многоэтапный способ развертывания приложений.
Это исключает использование зависимостей сборки в работающем контейнере.
6.избегайте ненужных привилегий.
Не привязывайтесь к специфичному UID.
Сделайте root владельцем всех исполняемых файлов и запретите в них запись. Пользователь приложения должен иметь права на исполнения файлов не но должен быть их владельцем!
7.Никогда не помещайте секреты или креды.Если приложение поддерживает конфигурацию через переменные окружения, используйте их для настройки секретов во время запуска контейнера (опция -e в команде docker run). Используйте конфигурационные файлы и точки монтирования (bind mount points) чтобы пробросить их в контейнер Docker.
8.Используйте COPY, если вам действительно не нужна функция ADD.
В некоторых случаях предпочтительнее использовать инструкцию RUN вместо ADD для загрузки пакета с помощью curl или wget, распаковать его, а затем удалить исходный файл за один шаг, сократив количество слоев.
9.Контекст сборки и dockerignore. Параметр “.” это сборочный контекст. Использование “.” в качестве контекста опасно так как вы можете скопировать конфиденциальные или не нужные файлы в контейнер.
10.Помните, что порядок инструкций в Dockerfile очень важен. Каждая из RUN, COPY, ADD и других инструкций создает новый слой, в то же время как объединение команд в группы позволит уменьшить их число.
Помимо этого, размещайте те команды, чей результат по вашему мнению будет реже изменяться и его будет проще закешировать — первыми. 
Так же запомните, что вызов команды rm, приведет к удалению файлов на следующем слое, но они все еще останутся доступными, так как финальный образ файловой системы составляется из всех предыдущих слоев. Ни в коем случае не копируйте конфиденциальные данные в контейнер, в надежде после удалить их — они останутся не видимы в финальном образе но все еще легко доступны.
11.OCI это Open Container Initiative — проект от Linux Foundation, цель которого — ввести стандартизацию в изначально хаотичный мир контейнеров Linux. https://opencontainers.org/
12.Удостоверьтесь, что ваш /var/run/docker.sock обладает правильными разрешениями (речь про права доступа на уровне файловой системы) и если вы публикуете демон Docker в сеть через TCP (что абсолютно не рекомендуется), убедитесь что он защищен.
13.Избегайте соблазна запуска от имени root, чтобы обойти проблемы с разрешениями или правами доступа, и вместо этого устраните реальную проблему.
14.Когда вы используете просто Docker или Docker Swarm включитай инструкцию HEALTHCHECK в свой Dockerfile, когда это возможно.
15.при выполнении вы можете ограничить возможности приложения минимально необходимым набором, используя флаг —cap-drop  в Docker или securityContext.capabilities.drop в Kubernetes. Таким образом, в случае, если ваш контейнер скомпрометирован, диапазон действий, доступных злоумышленнику, ограничен.
---------------------
10 плохих практик:

1.Попытка использовать контейнеры как виртуальные машины.
2.Создание запутанных Docker файлов.
3.Создание Dockerfiles, которые могут как-то влиять на внешнюю среду.
4.Смешивать образы, используемые для развертывания, с образами, используемыми для разработки.
5.Создание различных образов для каждой среды (dev, stage, prod).
6.Вытягивание кода из git на prod серверы и создание образов на лету.
7.Продвижение git-хэшей между командами.
8.Жесткое встраивание секретов в образы контейнеров.
9.Использование Docker в качестве CI/CD для бедных (так себе название пункта, я знаю, но тема там дальше раскроется).
10.Предположение о том что докер — это просто еще один способ упаковки
====================================================================================


====================================================================================
cmd vs entry-point
Факт 1: Требуется определить хотя бы одну инструкцию (ENTRYPOINT или CMD) (для запуска).
Факт 2: Если во время выполнения определена только одна из инструкций, то и CMD и ENTRYPOINT будут иметь одинаковый эффект.
Факт 3: И для CMD, и для ENTRYPOINT существуют режимы shell и exec.
Факт 4: Режим exec является рекомендуемым.
Факт 5: Нет оболочки? Нет переменных окружения.
Факт 6: Аргументы CMD присоединяются к концу инструкции ENTRYPOINT… иногда.
Факт 6a: Если вы используете режим shell для ENTRYPOINT, CMD игнорируется.
FACT 6b: При использовании режима exec для ENTRYPOINT аргументы CMD добавляются в конце.
Факт 6c: При использовании режима exec для инструкции ENTRYPOINT необходимо использовать режим exec и для инструкции CMD. Если этого не сделать, Docker попытается добавить sh -c в уже добавленные аргументы, что может привести к некоторым непредсказуемым результатам.
Факт 7: Инструкции ENTRYPOINT и CMD могут быть переопределены с помощью флагов командной строки.
Флаг --entrypoint может быть использован, чтобы переопределить инструкцию ENTRYPOINT:
docker run --entrypoint [my_entrypoint] test  
Все, что следует после названия образа в команде docker run, переопределяет инструкцию CMD:
docker run test [command 1] [arg1] [arg2]  
Используйте ENTRYPOINT, если вы не хотите, чтобы разработчики изменяли исполняемый файл, который запускается при запуске контейнера. Вы можете представлять, что ваш контейнер – исполняемая оболочка. Хорошей стратегией будет определить стабильную комбинацию параметров и исполняемого файла как ENTRYPOINT. Для нее вы можете (не обязательно) указать аргументы CMD по умолчанию, доступные другим разработчикам для переопределения.
Используйте только CMD (без определения ENTRYPOINT), если требуется, чтобы разработчики могли легко переопределять исполняемый файл. Если точка входа определена, исполняемый файл все равно можно переопределить, используя флаг --entrypoint. Но для разработчиков будет гораздо удобнее добавлять желаемую команду в конце строки docker run.
====================================================================================


====================================================================================
«df» отображает информацию об имени устройства, общем количестве блоков, общем дисковом пространстве, используемом дисковом пространстве, доступном дисковом пространстве и точках монтирования в файловой системе
df -hT /home  # -T == Type, -h Отображение информации о файловой системе в ГБ
df -k  # Отображение информации о файловой системе в байтах
df -m  # Отображение информации о файловой системе в мегабайтах
df -i  # информация о количестве используемых Inode и их процентное соотношение для файловой системы
-----------
«по каким причинам может возникнуть ошибка записи»?
Естественно так случится, если не останется свободных блоков файловой системы. Что можно в этом случае сделать? Кроме очевидного «удалить что-нибудь ненужное», следует помнить, что в файловых системах ext2,3 и 4 есть такая штука, как «Reserved block count». Это блоки доступные для записи только пользователю root. но если нужно оперативно решить вопрос, как временное решение можно сделать их доступными для всех, в результате чего появится немного свободного места:
root@ubuntu:/mnt# tune2fs -m 0 /dev/sdb1
tune2fs 1.42.9 (4-Feb-2014)
Setting reserved blocks percentage to 0% (0 blocks)

Что еще может быть? Еще возможна ситуация, когда свободные блоки есть, а ноды кончились. Такое обычно случается, если у вас в файловой системе куча файлов размером меньше размера блока файловой системы. Учитывая, что на 1 файл или директорию тратится 1 inode, а всего их имеем (для данной файловой системы) 65536 — ситуация более чем реальная. 
На случай если кончились inode, заклинаний не подскажу, т.к. их нет (если не прав, дайте знать). Так что для разделов в которых плодятся мелкие файлы следует грамотно выбирать файловую систему. Так например в btrfs inode не могут закончиться, т.к. динамически создаются новые при необходимости.
-----------
"du"
позволяет вывести размер всех файлов в определённой папке в байтах или в более удобном формате.
$ du опции /путь/к/папке
-L, --dereference - следовать по всем символическим ссылкам;
-S, --separate-dirs - не включать размер подпапок в размер папки;
-c, --total - выводить в конце общий размер всех папок;
-d, --max-depth - максимальная глубина вложенности директорий;
-a, --all - выводить размер для всех файлов, а не только для директорий, по умолчанию размер выводится только для папок;
-B, --block-size - указать единицы вывода размера, доступно: K,M,G,T,P,E,Z,Y для 1024 и KB, MB и так далее для 1000;
-t, --threshold - не учитывать файлы и папки с размером меньше указанного;
--time - отображать время последней модификации для файла или папки, вместо времени модификации можно выводить такие метки: atime, access, use, ctime;
-X, --exclude - исключить файлы из подсчёта;
-x, --one-file-system - пропускать примонтированные файловые системы;
====================================================================================


====================================================================================
load average. 
В 1993 году Linux-инженер обнаружил нелогичную работу средних значений нагрузки, и с помощью трёхстрочного патча навсегда изменил их с «со средних нагрузок на процессор» на «средние нагрузки на систему». С тех пор учитываются задачи в непрерываемом состоянии, так что средние нагрузки отражают потребность не только в процессорных, но и в дисковых ресурсах. Обновлённые метрики подсчитывают количество работающих и ожидающих работы процессов (ожидающих освобождения процессора, дисков и снятия непрерываемых блокировок). Они выводятся в виде трёх экспоненциально затухающих скользящих сумм, в уравнениях которых используются константы в 1, 5 и 15 минут. Эти три значения позволяют видеть динамику нагрузки, а самое большое из них может использоваться для относительного сравнения с ними самими.
С тех пор в ядре Linux всё активнее использовалось непрерываемое состояние, и сегодня оно включает в себя примитивы непрерываемой блокировки. Если считать среднее значение нагрузки мерой потребности в ресурсах в виде выполняемых и ожидающих потоков (а не просто потоков, которым нужны аппаратные ресурсы), то эта метрика уже работает так, как нам нужно.

cat /proc/loadavg
top - 16:48:42 up  4:12,  1 user,  load average: 25.25, 23.14, 23.37
$ uptime
 16:48:24 up  4:11,  1 user,  load average: 25.25, 23.40, 23.46
В Linux средние нагрузки — это (или пытаются быть) «средние значения нагрузки на систему», систему в целом. Они измеряют количество выполняемых потоков и ожидающих своей очереди (процессор, диск, непрерываемые блокировки). Иными словами, эта метрика отражает количество потоков, которые не простаивают полностью. Преимущество: учитывается потребность в разных ресурсах.
Рост средних нагрузок в Linux означает повышение потребности в ресурсах (процессоры, диски, некоторые блокировки), но вы не уверены, в каких. Чтобы пролить на это свет, можно использовать другие метрики. Например, для процессора:
использование каждого процессора (per-CPU utilization): например, используя mpstat -P ALL 1.
использование процессора для каждого процесса (per-process CPU utilization): например, top, pidstat 1 и так далее.
задержка очереди выполнения (диспетчера) для каждого потока (per-thread run queue (scheduler) latency): например, в /proc/PID/schedstats, delaystats, perf sched
задержка очереди выполнения процессора (CPU run queue latency): например, в /proc/schedstat, perf sched, моём инструменте runqlat bcc.
длина очереди выполнения процессора (CPU run queue length): например, используя vmstat 1 и колонку 'r', или мой инструмент runqlen bcc.
 если одноминутное среднее значение нагрузки гораздо ниже пятнадцатиминутного, то это важное свидетельство того, что я слишком поздно заметил проблему с производительностью.
====================================================================================


====================================================================================
pidstat - <PID>  # информация по определенному PID
где:
PID — Идентификационный номер задачи (процесса).
%usr -Процент CPU, который использовался при выполнении задачи на уровне пользователя (приложения) с или без «»nice приоритета. Обратите внимание, что это поле не включает время, затраченное на работу виртуального процессора.
%system — Процент CPU, используемый при выполнении задачи на системном уровне.
%guest — Процент CPU, используемый при выполнении задачи на виртуальной машине (работает виртуальный процессор).
%CPU — Сумарный процент CPU времени на потраченную задачу. В среде SMP, использование процессора на задачу будет разделена на общее число процессоров.
CPU — номер процессора, к которому прикреплена задача.
Command — Имя команды
-------------------------------------------------------------------------------------Мы можем использовать pidstat утилиту чтобы получить статистику ввода/вывода для некоторого процесса, используя флаг «-d». Для примера:
Где:

kB_rd/s — Это количество килобайтов когда процесс считал данные с диска за секунду.
kB_wr/s -Это количество килобайтов когда процесс считал или считает данные с диска за секунду.
kB_ccwr/s -Это количество килобайтов когда записи на диск былы отменены задачей.
-------------------------------------------------------------------------------------
Используйте «-r» опцию чтобы получить статистику об использования оперативной памяти и ошибок страниц:
pidstat -r -p ALL
Где:

minflt/s — Общее число незначительных сбоев, когда задача выполнялась каждую секунду и не требуют загрузки страничной памяти с диска.
majflt/s — Общее число незначительных сбоев, когда задача выполнялась каждую секунду и требуют загрузки страничной памяти с диска.
VSZ — Virtual Size: Виртуальное использование памяти для всех задач в килобайтах.
RSS — Resident Set Size: Использование физической памыти, но не свапа ( non-swapped) в килобайтах.
====================================================================================


====================================================================================
iostat – утилита, предназначенная для мониторинга использования дисковых разделов, входящая в набор sysstat.
iostat - сообщает об использовании ЦП и статистику ввода/вывода дисков. iostat собирает данные из файловой системы ргос, выдавая по одной строке для каждого физического устройства.
Первый отчет команды iostat содержит информацию, накопленную с момента загрузки системы до вызова команды iostat. В каждом следующем наборе выдается информация, собранная за предшествующий интервал времени (в данном случае # iostat 5 2 -N
 - за 5 секунд).
====================================================================================


====================================================================================
stdin 
Поток вывода ошибок.
stdout
Стандартный поток вывода данных для программ. 
stderr
Поток вывода ошибок.
------------------------------------------------------------------------------------
Перенаправление потоков
$ ls >1.txt
В этом примере мы направили stdout команды ls в файл 1.txt.
направить stderr команды rm:
$ rm example.txt 2>1.txt
десь мы использовали номер потока stderr (2). По умолчанию оператор > перенаправляет поток stdout, который имеет номер 1. Чтобы направить другой поток, надо перед оператором > поставить его номер.
$ rm exmple.txt >1.txt 2>&1
В этом примере мы направили поток stdout в файл 1.txt, а затем направили stderr туда же, куда направлен stdout с помощью оператора & перед номером потока.
-------------------------------------------------------------------------------------
rm -Rf `find . | grep -e '/.svn$'`
 оператор: `. Он забирает stdout из команды, которую он окружает и вставляет в данное место как строку.
 Получается, что мы запросили все файлы, выбрали из них папки с именем ".svn" и отдали результат как аргументы команде rm. В этом случае у нас будут проблемы если имена файлов и папок содержат пробелы. Исправляем ситуацию:

find . | grep -e '/.svn$' | xargs rm -Rf

Теперь мы отдаем нужные файлы команде xargs, которая вызывает rm -Rf и в качестве параметров использует свой stdin построчно. Задача решена.
====================================================================================


====================================================================================
set -e bash-scripting
https://ciksiti.com/ru/chapters/8557-what-set--e-do-in-bash
немедленный выход, если выходное состояние команды ненулевое.

Для отключения этой функции в дальнейшем в скрипте можно использовать команду "set +e bash-script"
====================================================================================


====================================================================================
Что происходит, когда компьютер включается?
------------------------------------------------------------------------------------
0) блок питания подает ток на мать > системный контроллер (проверяет, нужно ли подавать ток на остальные устройства компьютера)
1) при включении ток поступает на основные компоненты компьютера (CPU, RAM, BIOS, HDD)
2) системный контроллер загружает содержимое микросхемы BIOS в RAM
    BIOS (Basic Input/ Output system) - Базовая состема ввода-вывода, отвечает за загрузку компьютера, хранит данные на микросхеме, к-я питается от батарейки.
3) BIOS запусткает POST (Power On Self Test) - проверка работостпособности компонент компьютера.
4) BIOS ищет загрузчик, считывает его код и передает дальнейшее управление.
5) Загрузчик - собирательное название всех программ и драйверов, необходимых операционной системе для полноценной загрузки.
   - загрузчик включает нужный режим работы процессора
   - распределяет оперативную память, сгружает в нее файл с параметрами загрузки ОС
   - загружает драйверы, проверяет их цифровую подпись
   - подключает файловую систему
   - находит ядро, загружает его в RAM и передает ему управление
6) Ядро обеспечивает работоспособность системы и регулирует ключевые процессы  
   - смотрит какое железо подключено, какие драйвера нужны
   - считывает настройки системы, загружает скрипты с нужными параметрами
   - запускает слыжбы и демоны
   - загружает графику
   - включает систему входа пользователей
------------------------------------------------------------------------------------
Что происходит при загрузке Linux?
------------------------------------------------------------------------------------
BIOS => MBR => GRUB => KERNEL => INIT => RUNLEVEL

MBR - главная загрузочная запись, хранится в первом секторе hdd, например в /dev/sda.
  Состоит из трех компонент: загрузочная информация, информация о таблице разделов, 2 байта для проверки корректности mbr.
  Содержит информацию о GRUB.
MBR загружает и выполняет загрузчик GRUB.

 Все несколько усложнилось за последние годы. Сейчас уместней говорить о EFI.
«GUID Partition Table (GPT) является стандартным форматом размещения таблиц разделов на физическом жестком диске. Он является частью Extensible Firmware Interface (EFI) (Расширяемый Микропрограммный Интерфейс) — стандарта, предложенного Intel на смену отжившего BIOS, одного из последних реликтов первозданной IBM PC. EFI использует GPT там, где BIOS использует Главную загрузочную запись (MBR)....»

GRUB (Grand Unified Bootloader).
Загружает и выполняет образы ядра (vmlinuz) и initrd.
Конф файл - /boot/grub/grub.conf

KERNEL
 - монтирует файловую систему в соответствии с записью в grub.conf
 - выполняет программу /sbin/init (становится родительским процессом по отношению ко всем автоматически запускаемым в системе процессам)

INIT
 - смотрит в /etc/inittab для того чтобы определить уровень загрузки (cat /etc/inittab | grep initdefault)

RUNLEVEL (уровень выполнения программ)

Исходя из настроек по умолчанию, система выполнять файлы из директорий /etc/rc.d/rc[0..6].d/
В катологах программы, имя которых начинается с S (startup) и K (kill), для запуска и завершения соответственно.
Рядом с буквами, в названии, номера - соответствуют порядку запуска/завершения.

====================================================================================
Что такое сигналы в linux?
====================================================================================
Сигналы - один из способов взаимодействия между процессами.
Сигнал - это ассинхронное уведомление процесса о каком-либо событии.

Сигналы иногда описывают как системные прерывания. Когда сигнал послан процессу, операционная система прерывает выполнение процесса. Если процесс установил собственный обработчик сигнала, операционная система запускает этот обработчик, передав ему информацию о сигнале. Если процесс не установил обработчик, то выполняется обработчик по умолчанию.

Каждый сигнал является кодом - целым числом (от 1).

SIGKILL 9 Безусловное Завершение
  SIGKILL используется для немедленного прекращения процесса. Процесс будет завершен вместе с его потоками (если есть).
  Это жесткий способ убить процесс, и его следует использовать только как последнее средство.

SIGTERM (SIGnal и TERMinate)	15 Сигнал завершения (сигнал по умолчанию для утилиты kill)
  По умолчанию команда kill отправляет сигнал SIGTERM.

SIGTERM может обрабатываться, игнорироваться и блокироваться, но SIGKILL не может быть обработан или заблокирован.
С помощью SIGTERM процесс получает время для отправки информации своим родительским и дочерним процессам. Дочерние процессы обрабатываются init.
SIGTERM не убивает дочерние процессы. SIGKILL также убивает дочерние процессы.

====================================================================================
Что такое зомби-процесс в linux?
====================================================================================
Каждая программа, которая выполняется в linux, - это системный процесс, у которого есть свой идентификатор.

Каждый процесс может запускать дочерние процессы с помощью функции fork.
Такие процессы остаются под контролем родительского процесса и не могут быть завершены без его ведома. Если один из дочерних процессов завершился, а его родительский процесс не смог получить об этом информацию, такой дочерний процесс становится зомби.

Зомби процессы в linux не завершаются и убить их нельзя, даже с помощью sigkill, они будут висеть в памяти, пока не завершится их родительский процесс.

Посмотреть список замби-процессов:
ps -aux | grep defunct

Найти родителя (четвертая колонка):
ps -xal | grep defunct 

====================================================================================
Что такое процесс-сиротка в linux?
====================================================================================
Процесс-сирота в Linux — дочерний процесс, чей родительский процесс (или связь с ним) был завершён нештатно (не подав сигнала на завершение работы).

Обычно «сиротой» остаётся дочерний процесс после неожиданного завершения родительского, но возможно возникновение сервера-сироты (локального или сетевого) при неожиданном прерывании связи или завершении клиентского процесса.

Процессы-сироты расходуют системные ресурсы сервера и могут быть источником проблем.
====================================================================================


====================================================================================
127.0.0.1 и localhost
====================================================================================
127.0.0.1 — это IP-адрес, который называют «адресом циклической обратной связи» или «адресом loopback». Он указывает на локальное устройство, на котором выполняется программа. Когда отправляют запрос на этот адрес, он обрабатывается непосредственно на компьютере без отправки данных по сети.

localhost — это псевдоним для адреса 127.0.0.1, он удобен в использовании, так как представляет собой понятное для людей имя хоста. 
====================================================================================


====================================================================================
аппаратный сетевой интерфейс.
====================================================================================
Аппаратный сетевой интерфейс (также известный как сетевой адаптер, NIC — Network Interface Card или сетевая плата) — это физическое устройство, которое позволяет компьютеру или другому электронному устройству подключаться к сети (локальной или глобальной) и обмениваться данными с другими устройствами. Это "посредник" между устройством и сетью, преобразующий данные в форму, пригодную для передачи по кабелю или через беспроводное соединение.
------------------------------------------------------------------------------------
Основные функции:

Преобразование сигналов:
Переводит цифровые данные компьютера (биты) в электрические, оптические или радиосигналы (в зависимости от типа сети) и наоборот.

Управление передачей данных:
Обеспечивает корректную отправку и прием пакетов данных, контролирует их целостность.

MAC-адрес:
Каждый сетевой интерфейс имеет уникальный идентификатор — MAC-адрес (Media Access Control), который используется для идентификации устройства в локальной сети.
------------------------------------------------------------------------------------
Примеры аппаратных сетевых интерфейсов:

Ethernet-адаптер (проводное подключение через RJ-45).
Wi-Fi модуль (беспроводное подключение).
Bluetooth-адаптер.
Модем (для подключения к телефонным линиям или сотовым сетям).
------------------------------------------------------------------------------------
Где находится?

Встроенные: Интегрированы в материнскую плату (например, порт Ethernet на ноутбуке).
Внешние: Подключаются через USB, PCIe или другие интерфейсы (например, внешняя Wi-Fi-карта).
------------------------------------------------------------------------------------
Зачем нужен?
Без сетевого интерфейса устройство не может взаимодействовать с сетью. 

Он обеспечивает:
Подключение к интернету.
Обмен данными в локальной сети (например, между компьютерами в офисе).
Работу сетевых технологий (VPN, VoIP, онлайн-игры и т.д.).
------------------------------------------------------------------------------------
Важно:
Аппаратный интерфейс отличается от программного (например, сетевых интерфейсов в операционной системе, таких как eth0 в Linux или «Ethernet-адаптер» в Windows). Программная часть управляет настройками (IP-адрес, маршрутизация), а аппаратная — физической передачей данных.

Для работы сетевого адаптера требуются драйверы — программы, которые связывают его с операционной системой.
====================================================================================


====================================================================================
псевдодрайвер
====================================================================================
Псевдодрайвер (или псевдоустройство) — это программный компонент ядра операционной системы, который имитирует поведение физического устройства или предоставляет специфические сервисы, но не управляет реальным аппаратным оборудованием. Такие драйверы создаются для решения задач, не требующих взаимодействия с «железом», но нуждающихся в интеграции на уровне ядра.
------------------------------------------------------------------------------------
Основные особенности псевдодрайверов:

Не связаны с физическими устройствами

Они работают с виртуальными объектами, такими как:
Специальные файлы устройств (например, /dev/null, /dev/random в Linux).
Виртуальные сетевые интерфейсы (например, loopback).
Эмуляторы (например, виртуальные диски или TTY-устройства).

Реализуют логику, а не управление железом
Их задача — обрабатывать данные, эмулировать поведение устройств или предоставлять интерфейсы для взаимодействия между пользовательскими приложениями и ядром.

Интегрированы в ядро ОС
Как и обычные драйверы, они работают в привилегированном режиме, но не требуют наличия физического устройства.
------------------------------------------------------------------------------------
Примеры псевдодрайверов:

/dev/null
Виртуальное устройство, которое немедленно "уничтожает" все записанные в него данные и возвращает EOF при чтении.

/dev/random и /dev/urandom
Генерируют псевдослучайные числа на основе энтропии системы (например, шум от движений мыши или таймингов сетевых пакетов).

Loopback-интерфейс (lo в Linux)
Позволяет компьютеру обмениваться данными сам с собой через сетевой стек (используется для тестирования и локальных сервисов).

TUN/TAP
Виртуальные сетевые интерфейсы для создания VPN, эмуляции сетевых подключений или работы с виртуальными машинами.

FUSE (Filesystem in Userspace)
Позволяет создавать файловые системы в пользовательском пространстве, но использует псевдодрайвер в ядре для взаимодействия.
------------------------------------------------------------------------------------
Почему они называются «драйверами»?

Псевдодрайверы используют тот же механизм интеграции в ядро, что и обычные драйверы, чтобы:

Поддерживать стандартные интерфейсы (например, файлы устройств в /dev).
Обеспечивать единый API для приложений (через системные вызовы read(), write(), ioctl()).

Пример использования:
Когда вы запускаете VPN (например, OpenVPN), псевдодрайвер TUN/TAP создает виртуальный сетевой интерфейс, через который шифруются и передаются данные, хотя физического сетевого адаптера для этого не требуется.
====================================================================================


====================================================================================
 драйвер
====================================================================================
Драйвер в ядре операционной системы — это специальная программа, которая обеспечивает взаимодействие между аппаратным устройством и операционной системой. Драйверы работают на низком уровне (в пространстве ядра) и служат «переводчиками», преобразующими запросы ОС и приложений в команды, понятные конкретному устройству, и наоборот.
------------------------------------------------------------------------------------
Основные функции драйвера:

Управление аппаратурой
Контролирует работу устройства: включает/выключает его, настраивает режимы (например, энергосбережение), обрабатывает ошибки.

Обработка прерываний
Реагирует на сигналы от устройства (например, нажатие клавиши на клавиатуре или завершение передачи данных по сети).

Преобразование данных
Переводит данные из формата, понятного ОС (например, файлы), в формат, который принимает устройство (например, электрические сигналы для диска).

Предоставление API
Создает интерфейс для приложений и ОС, чтобы они могли работать с устройством через стандартные системные вызовы (read, write, ioctl и др.).
------------------------------------------------------------------------------------
Типы драйверов:

Драйверы устройств
Управляют конкретным железом: видеокартой, сетевой картой, принтером, SSD и т.д.

Драйверы файловых систем
Обеспечивают работу с разными форматами данных (NTFS, ext4, FAT32).

Виртуальные драйверы
Работают с эмулированными устройствами (например, виртуальными машинами).

Псевдодрайверы
Не связаны с физическим железом (как /dev/null или сетевой loopback), но используют механизмы драйверов для интеграции в ядро.
------------------------------------------------------------------------------------
Как драйверы интегрированы в ОС?

В виде модулей ядра:
Загружаются динамически (например, драйвер USB при подключении флешки). В Linux это .ko-файлы, в Windows — .sys.

Статически встроенные в ядро:
Компилируются вместе с ядром ОС (часто для критически важных устройств, например, базовых контроллеров).Как драйверы интегрированы в ОС?
В виде модулей ядра:
Загружаются динамически (например, драйвер USB при подключении флешки). В Linux это .ko-файлы, в Windows — .sys.

Статически встроенные в ядро:
Компилируются вместе с ядром ОС (часто для критически важных устройств, например, базовых контроллеров).
------------------------------------------------------------------------------------
Отличие драйверов от псевдодрайверов

Драйверы управляют реальным железом, обращаются к его регистрам, памяти и прерываниям.

Псевдодрайверы эмулируют устройства или предоставляют сервисы ядра, не взаимодействуя с физическими компонентами.
====================================================================================


====================================================================================
curl
====================================================================================
Curl (от Client URL) — это инструмент командной строки и библиотека (libcurl) для передачи данных между клиентом и сервером с использованием различных сетевых протоколов.
------------------------------------------------------------------------------------
Основные этапы работы curl

1) Разбор команды и параметров

Пользователь вводит команду вида curl [опции] [URL]. 
Curl анализирует аргументы:
  - Определяет протокол (HTTP, HTTPS, FTP, SFTP и др.) из URL.
  - Проверяет опции (например, -o для сохранения в файл, -H для добавления заголовков).

2) Разрешение DNS
Curl преобразует доменное имя из URL в IP-адрес через DNS-запрос (например, example.com → 93.184.216.34).

3) Установка соединения

Для HTTP/HTTPS: подключается к порту 80 (HTTP) или 443 (HTTPS).
Для FTP: использует порт 21.
Для других протоколов (SCP, SFTP, SMTP) — соответствующие порты.
Если указана опция --proxy, соединение проходит через прокси-сервер.

4) TLS/SSL-рукопожатие (для HTTPS)
Если используется HTTPS, curl:

Проверяет сертификат сервера (можно отключить опцией -k).
Согласовывает параметры шифрования (например, TLS 1.3).
Устанавливает защищенное соединение.

5) Отправка запроса
Curl формирует и отправляет запрос к серверу. 

Примеры:
HTTP GET: GET /index.html HTTP/1.1.
HTTP POST: POST /api/data с телом запроса (данные через -d или --data).
Загрузка файла по FTP: PUT local_file.txt.

6) Получение ответа
Сервер обрабатывает запрос и отправляет ответ. 

Curl:
Получает статус-код (например, 200 OK или 404 Not Found).
Сохраняет заголовки (если указана опция -i).
Записывает тело ответа (HTML, JSON, файл и т.д.).

7) Обработка данных

По умолчанию curl выводит тело ответа в терминал.
С опцией -o сохраняет данные в файл:
curl -o page.html https://example.com
С опцией -O сохраняет файл под именем из URL:
curl -O https://example.com/image.jpg

8) Закрытие соединения
После завершения передачи curl закрывает соединение.
====================================================================================


====================================================================================
ARP-таблица (Address Resolution Protocol table) — это структура данных, хранящаяся в памяти сетевых устройств (компьютеров, маршрутизаторов, коммутаторов), которая содержит соответствие IP-адресов устройств их MAC-адресам в локальной сети (LAN). Она используется для быстрого определения физического адреса (MAC) устройства по его сетевому адресу (IP), что необходимо для корректной доставки кадров данных на канальном уровне модели OSI.
------------------------------------------------------------------------------------
Как работает ARP и зачем нужна ARP-таблица?

1) ARP-запрос:
Когда устройство хочет отправить данные на определенный IP-адрес в локальной сети, но не знает соответствующий MAC-адрес, оно отправляет ARP-запрос в виде широковещательного сообщения (на MAC FF:FF:FF:FF:FF:FF).

Пример:
"У кого IP 192.168.1.5? Сообщите ваш MAC!"

2) ARP-ответ:
Устройство с указанным IP отвечает напрямую отправителю, сообщая свой MAC-адрес.

Пример:
"У меня IP 192.168.1.5, мой MAC — 00:1A:2B:3C:4D:5E".

3) Обновление ARP-таблицы:
Полученная пара IP → MAC сохраняется в ARP-таблице для последующего использования, чтобы избежать повторных запросов.
------------------------------------------------------------------------------------
Структура ARP-таблицы

Каждая запись обычно содержит:

1) IP-адрес (например, 192.168.1.1).
2) MAC-адрес (например, 00:1A:2B:3C:4D:5E).
3) Тип записи:
  - Динамическая — автоматически добавлена по результату AR-запроса (временная).
  - Статическая — введена вручную (постоянная).
4) Срок жизни (TTL) — время, после которого динамическая запись удаляется (обычно 2–20 минут).
------------------------------------------------------------------------------------
Вот как выглядит таблица на Linux (команда arp -a):

Address         HWtype  HWaddress           Flags   Mask
192.168.1.1     ether   00:1A:2B:3C:4D:5E   C       eth0
192.168.1.102   ether   AA:BB:CC:DD:EE:FF   C       eth0
------------------------------------------------------------------------------------
Когда вы пингуете соседний компьютер в локальной сети (ping 192.168.1.10), ваш компьютер сначала проверяет ARP-таблицу. Если записи нет, отправляется ARP-запрос, чтобы узнать MAC-адрес устройства с IP 192.168.1.10, и только потом отправляются ICMP-пакеты.
====================================================================================


====================================================================================
URL (Uniform Resource Locator) — это строка, которая указывает на местоположение ресурса в сети (веб-страницы, изображения, файла и т.д.) и определяет способ доступа к нему. URL состоит из нескольких компонентов, каждый из которых выполняет свою роль. 
------------------------------------------------------------------------------------
Основные компоненты URL:

1) Схема (Протокол)
Определяет протокол доступа к ресурсу. 

Примеры:
http:// — стандартный протокол.
https:// — защищенный HTTP (с шифрованием).
ftp:// — для передачи файлов.
mailto: — для email-адресов.

2) Авторизация (необязательно)
Логин и пароль для доступа к ресурсу (редко используется из-за низкой безопасности):

Формат: user:password@.

3) Домен (Хост)
Доменное имя или IP-адрес сервера, где расположен ресурс:

Может включать порт (по умолчанию для HTTP — 80, HTTPS — 443).

4) Путь (Path)
Указывает расположение ресурса на сервере (как путь к файлу в файловой системе):

Например: /images/photo.jpg или /api/v1/data.

5) Параметры запроса (Query)
Дополнительные данные, передаваемые серверу (начинаются с ? и разделяются &):

Формат: ?ключ1=значение1&ключ2=значение2.

6) Якорь (Фрагмент)
Ссылка на конкретную часть страницы (например, заголовок). Не отправляется на сервер, обрабатывается браузером:

Начинается с #.
------------------------------------------------------------------------------------
Дополнительные нюансы:

1) Кодирование символов: Спецсимволы (пробелы, кириллица) заменяются на %-коды (например, пробел → %20).
Пример: https://example.com/search?q=Hello%20World.

2) Относительные URL: Могут не содержать схему или домен, если ссылаются на ресурс в рамках текущего сайта (например, /about.html).

3) Поддомены: Часть домена перед основным именем (например, blog.example.com).

4) Порт: Уточняет, через какой порт обращаться к серверу. Если не указан, используется порт по умолчанию для схемы.
====================================================================================




tcp/ip
запросы. методы get post put delete option
dns port transtort layer 53 udp/tcp
dns cache
для чего нужны портs? 
tsl/ssl
 для чего нужен ip протокол
 arp протокол
 ttl
 http заголовки
 коды ответа 100 200 300 400 401 404 500 504
 
 
