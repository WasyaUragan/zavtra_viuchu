####################################################################################


====================================================================================
git vs gitlab
====================================================================================
Git (СКВ, VCS, Version Control Systems) — распределённая система контроля версий, которая даёт возможность разработчикам отслеживать изменения в файлах и работать над одним проектом совместно с коллегами. Она была разработана в 2005 году Линусом Торвальдсом, создателем Linux, чтобы другие разработчики могли вносить свой вклад в ядро Linux.
Существует три типа СКВ: локальная, централизованная и распределённая.
---------------------
Преимущества Git:
Бесплатный и open-source.
Небольшой и быстрый.
Резервное копирование.
Простое ветвление.
---------------------
GitHub — сервис онлайн-хостинга репозиториев, обладающий всеми функциями распределённого контроля версий и функциональностью управления исходным кодом — всё, что поддерживает Git и даже больше. 
---------------------
GitLab — это еще один веб-репозиторий git, который набирает популярность среди разработчиков проектов с открытым исходным кодом.
---------------------
В отличие от GitHub, GitLab предлагает бесплатные частные репозитории для проектов с открытым исходным кодом.
GitHub делает упор на высокую доступность и производительность своей инфраструктуры и делегирует другие сложные функции сторонним инструментам.
---------------------
GitLab, наоборот, фокусируется на включении всех функций на одной проверенной и хорошо интегрированной платформе; он обеспечивает все для полного жизненного цикла DevOps под одной крышей. 
---------------------
Фактически, если вы войдете на сайт GitHub, вам будет сложно думать, что вы не на GitLab. За прошедшие годы две службы управления репозиториями взяли друг у друга лучшие функции и интегрировались в свои платформы.
---------------------
Вот некоторые общие функции:
Запрос изменение (pull request)
Сторонние интеграции
Вилка (fork) / клонирование репозитория
Ревью кода
Фрагменты кода
Отслеживание проблем
Расширенное управление разрешениями
Поддержка Markdown (облегчённый язык разметки, созданный с целью обозначения форматирования в простом тексте, с максимальным сохранением его читаемости человеком, и пригодный для машинного преобразования в языки для продвинутых публикаций (HTML, Rich Text и других).)
====================================================================================


====================================================================================
gitlab ci vs jenkins
====================================================================================
Jenkins — это широко известный, гибкий CI/CD-инструмент, предназначенный для автоматизации множества задач, связанных с программными проектами. Jenkins полностью написан на Java, он выпущен под лицензией MIT. Он обладает мощным набором возможностей, направленных на автоматизацию задач, связанных со сборкой, тестированием, развёртыванием, интеграцией, выпуском программного обеспечения.
---------------------
Jenkins может работать на платформах macOS, Windows и Linux. Он может функционировать и в среде Docker, что позволяет организовать единообразное и быстрое выполнение автоматизированных задач. Этот инструмент, кроме того, может выполняться в виде сервлета (Сервлет является интерфейсом Java, реализация которого расширяет функциональные возможности сервера. Сервлет взаимодействует с клиентами посредством принципа запрос-ответ.) в контейнерах, поддерживающих Java, в таких, как Apache Tomcat и GlassFish. Установка Jenkins качественно документирована.
---------------------
Разработчики Jenkins создали ещё один проект, Jenkins X, который рассчитан на работу в среде Kubernetes. В Jenkins X интегрированы Helm, сервер Jenkins CI/CD, Kubernetes и другие инструменты, предназначенные для создания CI/CD-конвейеров, соответствующих передовым методам DevOps. Например, здесь используется GitOps.
---------------------
Плюсы Jenkins:
Среди широко известных особенностей Jenkins можно отметить простоту настройки, высокий уровень автоматизации различных операций и отличную документацию. 
---------------------
Развитая экосистема плагинов
В настоящее время существует более 1500 плагинов для Jenkins.
---------------------
Простая установка и настройка
---------------------
Наличие REST API
---------------------
Поддержка параллельного выполнения задач
Выполнение тестирования кода можно ускорить за счёт организации параллельной сборки проекта с использованием различных виртуальных машин.
---------------------
Поддержка работы в распределённых средах
====================================================================================
GitLab CI/CD
---------------------
GitLab CI/CD и основной проект GitLab написаны на Ruby и на Go. Они выпущены под лицензией MIT.
---------------------
Популярность
Это, к тому же, бесплатный CI/CD-инструмент, встроенный в платформу GitLab.
---------------------
Поддержка GitLab Pages и Jekyll
Jekyll — это генератор статических сайтов, который можно использовать в рамках системы GitLab Pages для создания сайтов на основе GitLab-репозиториев. Система берёт исходные материалы и генерирует на их основе готовый статический сайт. Управлять внешним видом и возможностями таких сайтов можно, редактируя файл _config.yml, используемый Jekyll.
---------------------
 Автоматическое масштабирование CI-раннеров, можно серьёзно сэкономить на стоимости аренды серверных мощностей.
---------------------
GitLab CI/CD позволяет выполнять параллельное тестирование различных веток кода.
Результаты испытаний удобно анализировать в интерфейсе системы. Это выгодно отличает GitLab CI/CD от Jenkins.
---------------------
Ограничение доступа к репозиториям
---------------------
Различия                                         Jenkins      GitLab CI/CD   
Мониторинг производительности приложений	Отсутствует	Имеется
Поддержка	                                Отсутствует	Имеется
Установка	                                Требуется	Не требуется
---------------------
GitLab CI/CD может полностью контролировать Git-репозитории. Речь идёт об управлении ветками репозиториев и о некоторых других возможностях. А вот Jenkins, хотя и умеет работать с репозиториями, не даёт такого же уровня контроля над ними, как GitLab CI/CD.
GitLab CI/CD поддерживает развитые средства управления задачами, работающие на уровне проектов. Эта сторона Jenkins развита слабее.
====================================================================================


====================================================================================
ansible - bare or vm, helm - kuber, terraform - cloud servers
Ansible — это программное решение для удаленного управления конфигурациями.
Helm — это средство упаковки с открытым исходным кодом, которое помогает установить приложения Kubernetes и управлять их жизненным циклом
Terraform – это инструмент от компании Hashicorp, помогающий декларативно управлять инфраструктрой. В данном случае не приходится вручную создавать инстансы, сети и т.д. в консоли вашего облачного провайдера; достаточно написать конфигурацию, в которой будет изложено, как вы видите вашу будущую инфраструктуру. Такая конфигурация создается в человеко-читаемом текстовом формате. Если вы хотите изменить вашу инфраструктуру, то редактируете конфигурацию и запускаете terraform apply. Terraform направит вызовы API к вашему облачному провайдеру, чтобы привести инфраструктуру в соответствие с конфигурацией, указанной в этом файле.
====================================================================================


====================================================================================
git pull vs git fetch
Грубо говоря, по дефолту git pull — это шоткод для последовательности двух команд: git fetch (получение изменений с сервера) и git merge (сливание в локальную копию).
====================================================================================


====================================================================================
virtualisation vs containerisation.
https://www.itc.by/kontejnery-i-virtualnye-mashiny-v-chem-klyuchevye-razlichiya/
  вм      вм2     вм3         прилож. прилож. прилож.
прилож  прилож   прилож          д   о   к   е   р
  ос      ос       ос                   ос
    ги пер ви зор                     сер вер
         ОС 
       СЕРВЕР
       
Хотя слой контейнеров обеспечивает уровень логической изоляции между контейнерами, общая ОС может представлять собой единую точку отказа для всех контейнеров в системе. 
В отличие от ВМ, контейнеры не изменяются.  
Аналогичным образом, программное обеспечение, работающее в контейнерах, не обновляется, как традиционное ПО. Вместо этого обновления включаются в новый образ контейнера, который может быть развернут там, где это необходимо.
Контейнеры не перемещаются, а воссоздаются на целевых компьютерах перед уничтожением исходного экземпляра.
Большое количество контейнеров, возможное в среде центра обработки данных, может быстрее нагрузить пропускную способность локальной сети.
ВМ имеют небольшое преимущество в производительности, поскольку ВМ не сталкиваются с потенциальной конкуренцией общей ОС.
ВМ включают постоянное хранилище с виртуальным жестким диском. Контейнеры изначально работают из памяти и требуют тщательного использования инструментов хранения, таких как Docker Data Volumes, для сохранения данных контейнера после его уничтожения.
Контейнеры используют меньше вычислительных ресурсов.
Контейнеры меньше и требуют меньше ресурсов, чем виртуальные машины, поэтому контейнеры могут масштабироваться — создаваться или уничтожаться — гораздо быстрее, чем виртуальные машины.
ВМ используют отдельные ОС и приложения, поэтому недостатки в безопасности одной ВМ не распространяются на другие ВМ в среде. Контейнеры используют общую ОС и могут быть подвержены влиянию дефектов в ОС, поэтому они не так безопасны, как ВМ. Однако контейнеры могут работать внутри ВМ в рамках гибридного подхода к развертыванию, что может помочь локализовать потенциальные уязвимости безопасности.
Контейнеры не могут быть легко обновлены в режиме реального времени. Вместо этого файлы контейнеров обновляются и приводятся к определенным версиям, а затем новый файл образа может быть развернут для внедрения обновлений.

Все инструменты контейнеризации — будь то Docker, LXC или systemd-nspawn,— основываются на двух подсистемах ядра Linux: namespaces и cgroups.
---------------------
namespaces
---------------------
Пространство имён (англ. namespace) — это механизм ядра Linux, обеспечивающий изоляцию процессов друг от друга.

Пространство имён	Что изолирует
     PID	        PID процессов
     NETWORK  	 Сетевые устройства, стеки, порты и т.п.
     USER          	ID пользователей и групп
     MOUNT	        Точки монтирования
     IPC	   SystemV IPC, очереди сообщений POSIX
     UTS	      Имя хоста и доменное имя NIS
---------------------
cgroups
---------------------  
Но для контейнеризации одной лишь изоляции ресурсов недостаточно. Если мы запускаем какое-либо приложение в изолированном окружении, мы должны быть уверены в том, что этому приложению выделено достаточно ресурсов и что оно не будет потреблять лишние ресурсы, нарушая тем самым работу остальной системы. Для решения этой задачи в ядре Linux имеется специальный механизм — cgroups (сокращение от control groups, контрольные группы). 
====================================================================================


====================================================================================
Docker — программное обеспечение для автоматизации развёртывания и управления приложениями в средах с поддержкой контейнеризации, контейнеризатор приложений.
dockerfile best practices.
1.Использование нескольких команд RUN для установки пакетов повлияет на производительность и эффективность процесса сборки. Использование одной команды RUN для установки всех пакетов и зависимостей поможет создать один кэшируемый юнит вместо нескольких.
2.Использование образов меньшего размера способствует быстрому развертыванию и снижает возможности для атак. Удалите ненужные зависимости
RUN apt-get update && apt-get -y install --no-install-recommends
3.Используйте официальный образ Docker.
Не используйте для образа latest тег. Latest тег со временем может получать критические изменения.
Используйте минимальную версию сборки.если вы будете стараться избегать привычки включать ненужные пакеты и открывать ненужные порты, тем самым вы уменьшите поверхность для атаки.
 Осторожно выбирайте базовый образ для ваших контейнеров (имеется ввиду инструкция FROM).
 Почаще обновляйте свои образы. 
 Публикуйте наружу только те порты, которые нужны вашему приложению, и избегайте таких портов, как SSH (22).
4.Сборка из исходного кода в изолированной (consistent) среде.
Мы должны избегать создания приложений в локальной среде.
5.Рекомендуется использовать многоэтапный способ развертывания приложений.
Это исключает использование зависимостей сборки в работающем контейнере.
6.избегайте ненужных привилегий.
Не привязывайтесь к специфичному UID.
Сделайте root владельцем всех исполняемых файлов и запретите в них запись. Пользователь приложения должен иметь права на исполнения файлов не но должен быть их владельцем!
7.Никогда не помещайте секреты или креды.Если приложение поддерживает конфигурацию через переменные окружения, используйте их для настройки секретов во время запуска контейнера (опция -e в команде docker run). Используйте конфигурационные файлы и точки монтирования (bind mount points) чтобы пробросить их в контейнер Docker.
8.Используйте COPY, если вам действительно не нужна функция ADD.
В некоторых случаях предпочтительнее использовать инструкцию RUN вместо ADD для загрузки пакета с помощью curl или wget, распаковать его, а затем удалить исходный файл за один шаг, сократив количество слоев.
9.Контекст сборки и dockerignore. Параметр “.” это сборочный контекст. Использование “.” в качестве контекста опасно так как вы можете скопировать конфиденциальные или не нужные файлы в контейнер.
10.Помните, что порядок инструкций в Dockerfile очень важен. Каждая из RUN, COPY, ADD и других инструкций создает новый слой, в то же время как объединение команд в группы позволит уменьшить их число.
Помимо этого, размещайте те команды, чей результат по вашему мнению будет реже изменяться и его будет проще закешировать — первыми. 
Так же запомните, что вызов команды rm, приведет к удалению файлов на следующем слое, но они все еще останутся доступными, так как финальный образ файловой системы составляется из всех предыдущих слоев. Ни в коем случае не копируйте конфиденциальные данные в контейнер, в надежде после удалить их — они останутся не видимы в финальном образе но все еще легко доступны.
11.OCI это Open Container Initiative — проект от Linux Foundation, цель которого — ввести стандартизацию в изначально хаотичный мир контейнеров Linux. https://opencontainers.org/
12.Удостоверьтесь, что ваш /var/run/docker.sock обладает правильными разрешениями (речь про права доступа на уровне файловой системы) и если вы публикуете демон Docker в сеть через TCP (что абсолютно не рекомендуется), убедитесь что он защищен.
13.Избегайте соблазна запуска от имени root, чтобы обойти проблемы с разрешениями или правами доступа, и вместо этого устраните реальную проблему.
14.Когда вы используете просто Docker или Docker Swarm включитай инструкцию HEALTHCHECK в свой Dockerfile, когда это возможно.
15.при выполнении вы можете ограничить возможности приложения минимально необходимым набором, используя флаг —cap-drop  в Docker или securityContext.capabilities.drop в Kubernetes. Таким образом, в случае, если ваш контейнер скомпрометирован, диапазон действий, доступных злоумышленнику, ограничен.
---------------------
10 плохих практик:

1.Попытка использовать контейнеры как виртуальные машины.
2.Создание запутанных Docker файлов.
3.Создание Dockerfiles, которые могут как-то влиять на внешнюю среду.
4.Смешивать образы, используемые для развертывания, с образами, используемыми для разработки.
5.Создание различных образов для каждой среды (dev, stage, prod).
6.Вытягивание кода из git на prod серверы и создание образов на лету.
7.Продвижение git-хэшей между командами.
8.Жесткое встраивание секретов в образы контейнеров.
9.Использование Docker в качестве CI/CD для бедных (так себе название пункта, я знаю, но тема там дальше раскроется).
10.Предположение о том что докер — это просто еще один способ упаковки
====================================================================================


====================================================================================
cmd vs entry-point
Факт 1: Требуется определить хотя бы одну инструкцию (ENTRYPOINT или CMD) (для запуска).
Факт 2: Если во время выполнения определена только одна из инструкций, то и CMD и ENTRYPOINT будут иметь одинаковый эффект.
Факт 3: И для CMD, и для ENTRYPOINT существуют режимы shell и exec.
Факт 4: Режим exec является рекомендуемым.
Факт 5: Нет оболочки? Нет переменных окружения.
Факт 6: Аргументы CMD присоединяются к концу инструкции ENTRYPOINT… иногда.
Факт 6a: Если вы используете режим shell для ENTRYPOINT, CMD игнорируется.
FACT 6b: При использовании режима exec для ENTRYPOINT аргументы CMD добавляются в конце.
Факт 6c: При использовании режима exec для инструкции ENTRYPOINT необходимо использовать режим exec и для инструкции CMD. Если этого не сделать, Docker попытается добавить sh -c в уже добавленные аргументы, что может привести к некоторым непредсказуемым результатам.
Факт 7: Инструкции ENTRYPOINT и CMD могут быть переопределены с помощью флагов командной строки.
Флаг --entrypoint может быть использован, чтобы переопределить инструкцию ENTRYPOINT:
docker run --entrypoint [my_entrypoint] test  
Все, что следует после названия образа в команде docker run, переопределяет инструкцию CMD:
docker run test [command 1] [arg1] [arg2]  
Используйте ENTRYPOINT, если вы не хотите, чтобы разработчики изменяли исполняемый файл, который запускается при запуске контейнера. Вы можете представлять, что ваш контейнер – исполняемая оболочка. Хорошей стратегией будет определить стабильную комбинацию параметров и исполняемого файла как ENTRYPOINT. Для нее вы можете (не обязательно) указать аргументы CMD по умолчанию, доступные другим разработчикам для переопределения.
Используйте только CMD (без определения ENTRYPOINT), если требуется, чтобы разработчики могли легко переопределять исполняемый файл. Если точка входа определена, исполняемый файл все равно можно переопределить, используя флаг --entrypoint. Но для разработчиков будет гораздо удобнее добавлять желаемую команду в конце строки docker run.
====================================================================================


====================================================================================
«df» отображает информацию об имени устройства, общем количестве блоков, общем дисковом пространстве, используемом дисковом пространстве, доступном дисковом пространстве и точках монтирования в файловой системе
df -hT /home  # -T == Type, -h Отображение информации о файловой системе в ГБ
df -k  # Отображение информации о файловой системе в байтах
df -m  # Отображение информации о файловой системе в мегабайтах
df -i  # информация о количестве используемых Inode и их процентное соотношение для файловой системы
-----------
«по каким причинам может возникнуть ошибка записи»?
Естественно так случится, если не останется свободных блоков файловой системы. Что можно в этом случае сделать? Кроме очевидного «удалить что-нибудь ненужное», следует помнить, что в файловых системах ext2,3 и 4 есть такая штука, как «Reserved block count». Это блоки доступные для записи только пользователю root. но если нужно оперативно решить вопрос, как временное решение можно сделать их доступными для всех, в результате чего появится немного свободного места:
root@ubuntu:/mnt# tune2fs -m 0 /dev/sdb1
tune2fs 1.42.9 (4-Feb-2014)
Setting reserved blocks percentage to 0% (0 blocks)

Что еще может быть? Еще возможна ситуация, когда свободные блоки есть, а ноды кончились. Такое обычно случается, если у вас в файловой системе куча файлов размером меньше размера блока файловой системы. Учитывая, что на 1 файл или директорию тратится 1 inode, а всего их имеем (для данной файловой системы) 65536 — ситуация более чем реальная. 
На случай если кончились inode, заклинаний не подскажу, т.к. их нет (если не прав, дайте знать). Так что для разделов в которых плодятся мелкие файлы следует грамотно выбирать файловую систему. Так например в btrfs inode не могут закончиться, т.к. динамически создаются новые при необходимости.
-----------
"du"
позволяет вывести размер всех файлов в определённой папке в байтах или в более удобном формате.
$ du опции /путь/к/папке
-L, --dereference - следовать по всем символическим ссылкам;
-S, --separate-dirs - не включать размер подпапок в размер папки;
-c, --total - выводить в конце общий размер всех папок;
-d, --max-depth - максимальная глубина вложенности директорий;
-a, --all - выводить размер для всех файлов, а не только для директорий, по умолчанию размер выводится только для папок;
-B, --block-size - указать единицы вывода размера, доступно: K,M,G,T,P,E,Z,Y для 1024 и KB, MB и так далее для 1000;
-t, --threshold - не учитывать файлы и папки с размером меньше указанного;
--time - отображать время последней модификации для файла или папки, вместо времени модификации можно выводить такие метки: atime, access, use, ctime;
-X, --exclude - исключить файлы из подсчёта;
-x, --one-file-system - пропускать примонтированные файловые системы;
====================================================================================


====================================================================================
load average. 
В 1993 году Linux-инженер обнаружил нелогичную работу средних значений нагрузки, и с помощью трёхстрочного патча навсегда изменил их с «со средних нагрузок на процессор» на «средние нагрузки на систему». С тех пор учитываются задачи в непрерываемом состоянии, так что средние нагрузки отражают потребность не только в процессорных, но и в дисковых ресурсах. Обновлённые метрики подсчитывают количество работающих и ожидающих работы процессов (ожидающих освобождения процессора, дисков и снятия непрерываемых блокировок). Они выводятся в виде трёх экспоненциально затухающих скользящих сумм, в уравнениях которых используются константы в 1, 5 и 15 минут. Эти три значения позволяют видеть динамику нагрузки, а самое большое из них может использоваться для относительного сравнения с ними самими.
С тех пор в ядре Linux всё активнее использовалось непрерываемое состояние, и сегодня оно включает в себя примитивы непрерываемой блокировки. Если считать среднее значение нагрузки мерой потребности в ресурсах в виде выполняемых и ожидающих потоков (а не просто потоков, которым нужны аппаратные ресурсы), то эта метрика уже работает так, как нам нужно.

cat /proc/loadavg
top - 16:48:42 up  4:12,  1 user,  load average: 25.25, 23.14, 23.37
$ uptime
 16:48:24 up  4:11,  1 user,  load average: 25.25, 23.40, 23.46
В Linux средние нагрузки — это (или пытаются быть) «средние значения нагрузки на систему», систему в целом. Они измеряют количество выполняемых потоков и ожидающих своей очереди (процессор, диск, непрерываемые блокировки). Иными словами, эта метрика отражает количество потоков, которые не простаивают полностью. Преимущество: учитывается потребность в разных ресурсах.
Рост средних нагрузок в Linux означает повышение потребности в ресурсах (процессоры, диски, некоторые блокировки), но вы не уверены, в каких. Чтобы пролить на это свет, можно использовать другие метрики. Например, для процессора:
использование каждого процессора (per-CPU utilization): например, используя mpstat -P ALL 1.
использование процессора для каждого процесса (per-process CPU utilization): например, top, pidstat 1 и так далее.
задержка очереди выполнения (диспетчера) для каждого потока (per-thread run queue (scheduler) latency): например, в /proc/PID/schedstats, delaystats, perf sched
задержка очереди выполнения процессора (CPU run queue latency): например, в /proc/schedstat, perf sched, моём инструменте runqlat bcc.
длина очереди выполнения процессора (CPU run queue length): например, используя vmstat 1 и колонку 'r', или мой инструмент runqlen bcc.
 если одноминутное среднее значение нагрузки гораздо ниже пятнадцатиминутного, то это важное свидетельство того, что я слишком поздно заметил проблему с производительностью.
====================================================================================


====================================================================================
pidstat - <PID>  # информация по определенному PID
где:
PID — Идентификационный номер задачи (процесса).
%usr -Процент CPU, который использовался при выполнении задачи на уровне пользователя (приложения) с или без «»nice приоритета. Обратите внимание, что это поле не включает время, затраченное на работу виртуального процессора.
%system — Процент CPU, используемый при выполнении задачи на системном уровне.
%guest — Процент CPU, используемый при выполнении задачи на виртуальной машине (работает виртуальный процессор).
%CPU — Сумарный процент CPU времени на потраченную задачу. В среде SMP, использование процессора на задачу будет разделена на общее число процессоров.
CPU — номер процессора, к которому прикреплена задача.
Command — Имя команды
-------------------------------------------------------------------------------------Мы можем использовать pidstat утилиту чтобы получить статистику ввода/вывода для некоторого процесса, используя флаг «-d». Для примера:
Где:

kB_rd/s — Это количество килобайтов когда процесс считал данные с диска за секунду.
kB_wr/s -Это количество килобайтов когда процесс считал или считает данные с диска за секунду.
kB_ccwr/s -Это количество килобайтов когда записи на диск былы отменены задачей.
-------------------------------------------------------------------------------------
Используйте «-r» опцию чтобы получить статистику об использования оперативной памяти и ошибок страниц:
pidstat -r -p ALL
Где:

minflt/s — Общее число незначительных сбоев, когда задача выполнялась каждую секунду и не требуют загрузки страничной памяти с диска.
majflt/s — Общее число незначительных сбоев, когда задача выполнялась каждую секунду и требуют загрузки страничной памяти с диска.
VSZ — Virtual Size: Виртуальное использование памяти для всех задач в килобайтах.
RSS — Resident Set Size: Использование физической памыти, но не свапа ( non-swapped) в килобайтах.
====================================================================================


====================================================================================
iostat – утилита, предназначенная для мониторинга использования дисковых разделов, входящая в набор sysstat.
iostat - сообщает об использовании ЦП и статистику ввода/вывода дисков. iostat собирает данные из файловой системы ргос, выдавая по одной строке для каждого физического устройства.
Первый отчет команды iostat содержит информацию, накопленную с момента загрузки системы до вызова команды iostat. В каждом следующем наборе выдается информация, собранная за предшествующий интервал времени (в данном случае # iostat 5 2 -N
 - за 5 секунд).
====================================================================================


====================================================================================
stdin 
Поток вывода ошибок.
stdout
Стандартный поток вывода данных для программ. 
stderr
Поток вывода ошибок.
------------------------------------------------------------------------------------
Перенаправление потоков
$ ls >1.txt
В этом примере мы направили stdout команды ls в файл 1.txt.
направить stderr команды rm:
$ rm example.txt 2>1.txt
десь мы использовали номер потока stderr (2). По умолчанию оператор > перенаправляет поток stdout, который имеет номер 1. Чтобы направить другой поток, надо перед оператором > поставить его номер.
$ rm exmple.txt >1.txt 2>&1
В этом примере мы направили поток stdout в файл 1.txt, а затем направили stderr туда же, куда направлен stdout с помощью оператора & перед номером потока.
-------------------------------------------------------------------------------------
rm -Rf `find . | grep -e '/.svn$'`
 оператор: `. Он забирает stdout из команды, которую он окружает и вставляет в данное место как строку.
 Получается, что мы запросили все файлы, выбрали из них папки с именем ".svn" и отдали результат как аргументы команде rm. В этом случае у нас будут проблемы если имена файлов и папок содержат пробелы. Исправляем ситуацию:

find . | grep -e '/.svn$' | xargs rm -Rf

Теперь мы отдаем нужные файлы команде xargs, которая вызывает rm -Rf и в качестве параметров использует свой stdin построчно. Задача решена.
====================================================================================


====================================================================================
set -e bash-scripting
https://ciksiti.com/ru/chapters/8557-what-set--e-do-in-bash
немедленный выход, если выходное состояние команды ненулевое.
It's not universally considered bad practice. As with many disfavored language construct, it has its place. The main problem with it is that the behavior in edge cases is somewhat non-intuitive. – 
It's recommended to use:
trap 'do_something' ERR
------------------------------------------------------------------------------------
set +e bash-script
====================================================================================


====================================================================================




















sigterm, sigkill, 15 vs 9 signal
процесс зомби. процесс сиротка

127.0.0.1 localhost
аппаратный сетевой интерфейс vs псевдодрайвер в ядре операционной системы
curl howitworks
из чего состоит урл
tcp/ip
запросы. методы get post put delete option
dns port transtort layer 53 udp/tcp
dns cache
для чего нужны портs? 
tsl/ssl
 для чего нужен ip протокол
 arp протокол
 ttl
 http заголовки
 коды ответа 100 200 300 400 401 404 500 504
 
 
